{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T02:30:55.439544Z",
     "start_time": "2024-10-16T02:30:39.000812Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T02:48:43.785953Z",
     "start_time": "2024-10-16T02:48:43.702986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 读取数据\n",
    "data = load_dataset('csv', data_files='weibo_senti_100k.csv', split='train')\n",
    "data"
   ],
   "id": "e87814cad7458b00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'review'],\n",
       "    num_rows: 119988\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T02:48:45.861389Z",
     "start_time": "2024-10-16T02:48:45.842252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data.filter(lambda x: x['review'] is not None and x['label'] is not None)\n",
    "data"
   ],
   "id": "3c8967c68de23feb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'review'],\n",
       "    num_rows: 119988\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T02:48:49.821382Z",
     "start_time": "2024-10-16T02:48:49.774436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data.train_test_split(test_size=0.2)\n",
    "data"
   ],
   "id": "7421e012723e646d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 95990\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 23998\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T02:54:00.538802Z",
     "start_time": "2024-10-16T02:54:00.501151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "def process_function(data):\n",
    "    data['tokens'] = \" \".join(jieba.lcut(data['review']))\n",
    "    tokenized_data = tokenizer(data['tokens'], max_length=128, truncation=True)\n",
    "    tokenized_data['labels'] = data['label']\n",
    "    return tokenized_data"
   ],
   "id": "e0113685a1957d2c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DameJ\\.conda\\envs\\d2l-zh\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T02:38:26.388840Z",
     "start_time": "2024-10-16T02:38:26.374798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 分词\n",
    "def chinese_word_cut(text):\n",
    "    text['tokens'] = \" \".join(jieba.lcut(text['review']))\n",
    "    return text"
   ],
   "id": "2391af4a2969d97d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T02:55:45.784278Z",
     "start_time": "2024-10-16T02:54:18.686899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_dataset = data.map(process_function, remove_columns=data['train'].column_names)\n",
    "tokenized_dataset"
   ],
   "id": "1a97b58b3bdf4e34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/95990 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a26f1b3fc8054d8e9a036930a76b4800"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/23998 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53984cbb763445ebadb6711432b78698"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 95990\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 23998\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:09:56.118291Z",
     "start_time": "2024-10-14T15:09:55.547318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建模型和优化器\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=2)\n",
    "model.config"
   ],
   "id": "e252314de820dc44",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\DameJ\\.conda\\envs\\d2l-zh\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import evaluate\n",
    "\n",
    "acc_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')"
   ],
   "id": "bf62da245cbb05b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_metrics(eval_predict):\n",
    "    preds, labels = eval_predict\n",
    "    preds = preds.argmax(axis=1)\n",
    "    acc = acc_metric.compute(predictions=preds, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1\n",
    "    }"
   ],
   "id": "3d26a9227ece7561"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=128,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    metric_for_best_model='accuracy',\n",
    "    load_best_model_at_end=True\n",
    ")"
   ],
   "id": "bb8a32da418c01bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "f659ae3f17345ac4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 使用peft库的lora进行微调\n",
    "trainer.train()"
   ],
   "id": "c6b2c0fded8843d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train()",
   "id": "681e17cd78db0255"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.evaluate(tokenized_dataset['test'])",
   "id": "a7c94ac286455f3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa3215cc1bd1c627"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
